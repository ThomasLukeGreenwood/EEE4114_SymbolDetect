{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jana\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining all my functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moments(all_images): #takes in array of vector images\n",
    "    momentsArray = []\n",
    "    for image in all_images:\n",
    "        # Calculate mean\n",
    "        mean = np.mean(image)\n",
    "\n",
    "        # Calculate standard deviation\n",
    "        std_dev = np.std(image)\n",
    "\n",
    "        # Calculate skewness\n",
    "        skewness = skew(image.reshape(-1))  # Reshape to 1D array for skew function\n",
    "\n",
    "        # Calculate kurtosis\n",
    "        kurt = kurtosis(image.reshape(-1))  # Reshape to 1D array for kurtosis function\n",
    "        \n",
    "        momentsArray.append([mean, std_dev, skewness, kurt])\n",
    "    return np.array(momentsArray)\n",
    "\n",
    "def calculate_hu_moments(all_images): #takes in vector\n",
    "    momentsArray = []\n",
    "    for image_array in all_images:\n",
    "        cv2.imwrite('myImage.png', image_array) #convert vector to image\n",
    "        image = cv2.imread('myImage.png', cv2.IMREAD_GRAYSCALE) #read in image as grayscale (needs to be grayscale for moments function)\n",
    "        _,image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY) \n",
    "        \n",
    "        #calculate moments\n",
    "        moments = cv2.moments(image) \n",
    "        \n",
    "        # Calculate Hu Moments\n",
    "        huMoments = cv2.HuMoments(moments)\n",
    "        momentsArray.append(huMoments)\n",
    "        \n",
    "    return np.array(momentsArray)\n",
    "\n",
    "def combine_inputs(all_images): #takes in array of vector images; outputs 2D vector (one 1D array dedicated to each image)\n",
    "    #moments\n",
    "    moments_array = calculate_moments(all_images) #np array of stats for each image\n",
    "    \n",
    "    #hu moments\n",
    "    hu_moments_array = calculate_hu_moments(all_images) #np array of hu moments for each image\n",
    "\n",
    "    #flatten arrays\n",
    "    all_images_flat = tf.keras.layers.Flatten()(all_images)\n",
    "    hu_moments_flat = tf.keras.layers.Flatten()(hu_moments_array)\n",
    "\n",
    "    return np.concatenate((all_images_flat, hu_moments_flat, moments_array), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For initial development purposes, I'm using the mnist dataset of handdrawn digits.\n",
    "This should be removed for actual project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist #collect data\n",
    "\n",
    "#split data into training and testing data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#defining inputs with mnist data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_train_with_moments \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m x_test_with_moments \u001b[38;5;241m=\u001b[39m combine_inputs(x_test)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#normalise data\u001b[39;00m\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mcombine_inputs\u001b[1;34m(all_images)\u001b[0m\n\u001b[0;32m     37\u001b[0m moments_array \u001b[38;5;241m=\u001b[39m calculate_moments(all_images) \u001b[38;5;66;03m#np array of stats for each image\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#hu moments\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m hu_moments_array \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_hu_moments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_images\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#np array of hu moments for each image\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#flatten arrays\u001b[39;00m\n\u001b[0;32m     43\u001b[0m all_images_flat \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten()(all_images)\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mcalculate_hu_moments\u001b[1;34m(all_images)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_array \u001b[38;5;129;01min\u001b[39;00m all_images:\n\u001b[0;32m     22\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmyImage.png\u001b[39m\u001b[38;5;124m'\u001b[39m, image_array) \u001b[38;5;66;03m#convert vector to image\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmyImage.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_GRAYSCALE\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#read in image as grayscale (needs to be grayscale for moments function)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     _,image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(image, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY) \n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m#calculate moments\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#defining inputs with mnist data\n",
    "x_train_with_moments = combine_inputs(x_train)\n",
    "x_test_with_moments = combine_inputs(x_test)\n",
    "\n",
    "#normalise data\n",
    "x_train_with_moments = tf.keras.utils.normalize(x_train_with_moments, axis = 1)\n",
    "x_test_with_moments = tf.keras.utils.normalize(x_test_with_moments, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For initial development purposes, this is the NN I've been using. Not at all optimised for this application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "#model.add(tf.keras.layers.Flatten(input_shape=(28, 28))) - only needs to be used if just using mnist data and not extra info\n",
    "model.add(tf.keras.layers.Dense(128, activation = 'relu'))  #add dense layer, where each neuron is connected to each neuron of next layer\n",
    "model.add(tf.keras.layers.Dense(128, activation = 'relu')) \n",
    "model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax')) #each unit represents number (0-9); softmax ensures all outputs add up to 1 (essentially outputs are percentages)\n",
    "                                                            \n",
    "#compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#train the model\n",
    "model.fit(x_train, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
